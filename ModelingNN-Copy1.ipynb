{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Functions import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/TweetsOriginal.csv', encoding = 'ISO-8859-1')\n",
    "df.rename(columns = {'tweet_text': 'tweet', 'is_there_an_emotion_directed_at_a_brand_or_product': 'emotion'}, inplace = True)\n",
    "df.drop('emotion_in_tweet_is_directed_at', axis = 1, inplace = True)\n",
    "\n",
    "df.emotion = df.emotion.replace({'Negative emotion': 0, 'Positive emotion': 1, 'No emotion toward brand or product': None, \n",
    "                                \"I can't tell\": None})\n",
    "df.dropna(subset = ['emotion', 'tweet'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Value Counts\n",
      "1.0    2978\n",
      "0.0     570\n",
      "Name: emotion, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  emotion\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...      0.0\n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...      1.0\n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...      1.0\n",
       "3  @sxsw I hope this year's festival isn't as cra...      0.0\n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...      1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Original Value Counts')\n",
    "print(df.emotion.value_counts())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df = df[df.emotion == 1]\n",
    "neg_df = df[df.emotion ==0]\n",
    "\n",
    "resamp_pos = resample(pos_df, n_samples = 600, replace = False, random_state = 10)\n",
    "\n",
    "new_df = neg_df.append(resamp_pos, ignore_index = True)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(new_df.tweet, new_df.emotion, stratify = new_df.emotion, random_state = 10, \n",
    "                                                   train_size = .85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled Value Counts\n",
      "1.0    600\n",
      "0.0    570\n",
      "Name: emotion, dtype: int64\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Xtrain Value Value Counts\n",
      "1.0    510\n",
      "0.0    484\n",
      "Name: emotion, dtype: int64\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "XTest value Counts\n",
      "1.0    90\n",
      "0.0    86\n",
      "Name: emotion, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Resampled Value Counts')\n",
    "print(new_df.emotion.value_counts())\n",
    "print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "\n",
    "print('Xtrain Value Value Counts')\n",
    "print(y_train.value_counts())\n",
    "print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "\n",
    "print('XTest value Counts')\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 1000 \n",
    "embedding_dim = 16\n",
    "max_length = 280\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "oov_tok = '<OOV>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token = oov_tok)\n",
    "\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "\n",
    "train_seq = tokenizer.texts_to_sequences(x_train)\n",
    "train_seq = pad_sequences(train_seq, maxlen = max_length, padding = padding_type, truncating = trunc_type)\n",
    "test_seq = tokenizer.texts_to_sequences(x_test)\n",
    "test_seq = pad_sequences(test_seq, maxlen = max_length, padding = padding_type, truncating = trunc_type)\n",
    "\n",
    "test_labels = y_test.values\n",
    "train_labels = y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten \n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, BatchNormalization, Embedding, LSTM, Bidirectional\n",
    "from keras import regularizers\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(): \n",
    "    \n",
    "    model = Sequential() \n",
    "    model.add(Embedding(vocab_size, embedding_dim, input_length = max_length))\n",
    "    model.add(LSTM(embedding_dim, return_sequences = False))\n",
    "    model.add(Dense(32, activation = 'relu'))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 280, 16)           16000     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 16)                2112      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 18,689\n",
      "Trainable params: 18,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 994 samples, validate on 176 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 1070 of 27941 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 3019 of 27941 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 5375 of 27941 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 8489 of 27941 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 13249 of 27941 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 18526 of 27941 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 22750 of 27941 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 25527 of 27941 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "992/994 [============================>.] - ETA: 0s - loss: 0.6938 - acc: 0.5020- ETA: 3s - loss: 0.6933 - acc: 0.50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 1486 of 27941 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 3523 of 27941 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 6084 of 27941 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 9563 of 27941 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 14710 of 27941 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 20036 of 27941 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 23527 of 27941 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 26321 of 27941 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 3945 of 11549 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 9902 of 11549 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "994/994 [==============================] - 204s 205ms/step - loss: 0.6938 - acc: 0.5010 - val_loss: 0.6929 - val_acc: 0.5114\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69290, saving model to ../Weights/Test-ModelCheckpointWeights.h5\n",
      "Epoch 2/10\n",
      "994/994 [==============================] - 13s 13ms/step - loss: 0.6931 - acc: 0.5131 - val_loss: 0.6930 - val_acc: 0.5114\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.69290\n",
      "Epoch 3/10\n",
      "994/994 [==============================] - 13s 13ms/step - loss: 0.6931 - acc: 0.5131 - val_loss: 0.6929 - val_acc: 0.5114: 0.6930 - acc: \n",
      "\n",
      "Epoch 00003: val_loss improved from 0.69290 to 0.69289, saving model to ../Weights/Test-ModelCheckpointWeights.h5\n",
      "Epoch 4/10\n",
      "496/994 [=============>................] - ETA: 5s - loss: 0.6930 - acc: 0.5121"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', verbose = 1, patience=5)\n",
    "model_checkpoint = ModelCheckpoint(f'../Weights/Test-ModelCheckpointWeights.h5', verbose = 1, save_best_only=True,\n",
    "                                  monitor = 'val_loss')\n",
    "lr_plat = ReduceLROnPlateau(patience = 3, mode = 'min')\n",
    "\n",
    "calls = [early_stopping, model_checkpoint]\n",
    "epochs = 10 \n",
    "batch_size = 16\n",
    "\n",
    "model_history = model.fit(train_seq, train_labels, epochs = epochs, batch_size = batch_size, \n",
    "                         validation_data = (test_seq, test_labels), callbacks = calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nn_model(x, model_type, act):\n",
    "    model = Sequential()\n",
    "\n",
    "    if model_type == 'embedding':\n",
    "        model.add(Embedding(5000, 100, input_length = len(x[0]), trainable = False, name = 'Input'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(32, activation = act))\n",
    "        \n",
    "    elif model_type == 'normal': \n",
    "        model.add(Dense(32, activation = act, input_shape = x[0].shape, name = 'Input'))\n",
    "        model.add(Dense(64, activation = act))\n",
    "        model.add(Dense(128, activation = act))\n",
    "\n",
    "        \n",
    "    elif model_type == 'cnn': \n",
    "#         model.add(Embedding(5000, 100, input_length = len(x[0]), trainable = False,  name = 'Input'))\n",
    "        model.add(Conv1D(128, 5, activation = act, ))\n",
    "        model.add(GlobalMaxPooling1D())\n",
    "        model.add(Dense(64, activation = act))\n",
    "    \n",
    "    elif model_type == 'LSTM': \n",
    "        model.add(Embedding(5000, 100, input_length = len(x[0]), trainable = False,  name = 'Input'))\n",
    "        model.add(LSTM(128, activation = act))\n",
    "\n",
    "\n",
    "    model.add(Dense(1, activation = 'sigmoid', name = 'OutputLayer'))\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normal\n",
    "model_type = 'normal'\n",
    "act = 'sigmoid'\n",
    "model = get_nn_model(x_train, model_type, act)\n",
    "print(model.summary())\n",
    "\n",
    "#cnn\n",
    "early_stopping = EarlyStopping(monitor='val_loss', verbose = 1, patience=20)\n",
    "model_checkpoint = ModelCheckpoint(f'../Weights/{model_type.upper()}_{act}-ModelCheckpointWeights.h5', verbose = 1, save_best_only=True,\n",
    "                                  monitor = 'val_loss')\n",
    "lr_plat = ReduceLROnPlateau(patience = 3, mode = 'min')\n",
    "\n",
    "callbacks = [early_stopping, model_checkpoint]\n",
    "epochs = 100 \n",
    "batch_size= 32\n",
    "\n",
    "model_history = model.fit(x_train, y_train, epochs = epochs, batch_size = batch_size, \n",
    "                         validation_data = (x_test, y_test), callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(model_history, model_type, act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_nn_model(x_train, model_type, act)\n",
    "model.load_weights(f'../Weights/{model_type.upper()}_{act}-ModelCheckpointWeights.h5')\n",
    "\n",
    "get_roc_auc(model,model_type, act, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_prob = model.predict(x_test).ravel() \n",
    "y_train_prob = model.predict(x_train).ravel() \n",
    "\n",
    "plot_cm(y_train = y_train, y_test = y_test, y_train_prob = y_train_prob,\n",
    "                      y_test_prob = y_test_prob,classes = ['Negative', 'Positive'], thresholds = [.2, .5,.6], \n",
    "        model_type = model_type, act = act)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normal\n",
    "model_type = 'cnn'\n",
    "act = 'relu'\n",
    "model = get_nn_model(x_train, model_type, act)\n",
    "print(model.summary())\n",
    "\n",
    "#cnn\n",
    "early_stopping = EarlyStopping(monitor='val_loss', verbose = 1, patience=5)\n",
    "model_checkpoint = ModelCheckpoint(f'../Weights/{model_type.upper()}_{act}-ModelCheckpointWeights.h5', verbose = 1, save_best_only=True,\n",
    "                                  monitor = 'val_loss')\n",
    "lr_plat = ReduceLROnPlateau(patience = 3, mode = 'min')\n",
    "\n",
    "callbacks = [early_stopping, model_checkpoint]\n",
    "epochs = 100 \n",
    "batch_size= 32\n",
    "\n",
    "model_history = model.fit(x_train, y_train, epochs = epochs, batch_size = batch_size, \n",
    "                         validation_data = (x_test, y_test), callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(model_history, model_type, act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_nn_model(x_train, model_type, act)\n",
    "model.load_weights(f'../Weights/{model_type.upper()}_{act}-ModelCheckpointWeights.h5')\n",
    "\n",
    "get_roc_auc(model,model_type, act, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_prob = model.predict(x_test).ravel() \n",
    "y_train_prob = model.predict(x_train).ravel() \n",
    "\n",
    "plot_cm(y_train = y_train, y_test = y_test, y_train_prob = y_train_prob,\n",
    "                      y_test_prob = y_test_prob,classes = ['Negative', 'Positive'], thresholds = [.2, .5,.6], \n",
    "        model_type = model_type, act = act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
