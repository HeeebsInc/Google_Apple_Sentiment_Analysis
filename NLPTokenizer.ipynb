{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Item</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Emotion_New</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text                Item  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "3  @sxsw I hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...              Google   \n",
       "\n",
       "            Emotion  Emotion_New  \n",
       "0  Negative emotion          0.0  \n",
       "1  Positive emotion          2.0  \n",
       "2  Positive emotion          2.0  \n",
       "3  Negative emotion          0.0  \n",
       "4  Positive emotion          2.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/TweetsNew.csv').drop('Unnamed: 0', axis =1)\n",
    "df.dropna(subset = ['Text', 'Emotion_New'], inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8936 entries, 0 to 9092\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Text         8936 non-null   object \n",
      " 1   Item         3282 non-null   object \n",
      " 2   Emotion      8936 non-null   object \n",
      " 3   Emotion_New  8936 non-null   float64\n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 349.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.tokenize import RegexpTokenizer, sent_tokenize, word_tokenize, TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enchant\n",
    "from pprint import pprint\n",
    "\n",
    "en_us = enchant.Dict(\"en_US\")\n",
    "\n",
    "phrases = df.Text.values\n",
    "\n",
    "\n",
    "for i, phrase in enumerate(df.Text):\n",
    "    phrases[i] = ' '.join(w for w in phrase.split() if en_us.check(w))\n",
    "\n",
    "df.Text = phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tweet_token = TweetTokenizer()\n",
    "df.Text = df.Text.map(lambda x: tweet_token.tokenize(x.lower()))\n",
    "df.Text = df.Text.map(lambda x: ' '.join(x))\n",
    "df.Text= df.Text.map(lambda x: word_tokenizer.tokenize(x.lower()))\n",
    "df.Text = df.Text.map(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df.Text, df.Emotion_New, stratify = df.Emotion_New, train_size = .75, \n",
    "                                                   random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1006             grown men playing google party speakeasy\n",
       "8275    the secret search sauce google and spill the b...\n",
       "8081    4 finding an in the back of austin yellow drop...\n",
       "5779    rt giving added value to location based servic...\n",
       "1679    hoping a or popup store opens up so i can get ...\n",
       "                              ...                        \n",
       "8709    within hours of buying an glenda watson cerebr...\n",
       "6120    rt make sure you re donating to the japanese r...\n",
       "5476                      rt apple to open pop up shop at\n",
       "881     purchased mexican mavis by boy bear on first l...\n",
       "3771      rt going to at check in while in location based\n",
       "Name: Text, Length: 6702, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words = stop, max_features = 5000, ngram_range=(1,3))\n",
    "clean_train = x_train.values\n",
    "clean_test = x_test.values\n",
    "\n",
    "train_features =vectorizer.fit_transform(clean_train).toarray()\n",
    "test_features = vectorizer.fit_transform(clean_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in train_features[0]: \n",
    "    if i != 0: \n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#unsampled \n",
    "\n",
    "pickle.dump(train_features, open('../Pickles/x_train.p', 'wb'))\n",
    "pickle.dump(test_features, open('../Pickles/x_test.p', 'wb'))\n",
    "pickle.dump(y_train, open('../Pickles/y_train.p', 'wb'))\n",
    "pickle.dump(y_test, open('../Pickles/y_test.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6702, 5000) (2234, 5000)\n",
      "(6702,) (2234,)\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape, test_features.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
