{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier, RidgeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, plot_confusion_matrix, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "\n",
    "pd.options.display.max_rows = 35 \n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6702, 5000) (2234, 5000)\n",
      "(6702,) (2234,)\n"
     ]
    }
   ],
   "source": [
    "def get_pickles(): \n",
    "    x_train = pickle.load(open('../Pickles/x_train.p', 'rb'))\n",
    "    x_test = pickle.load(open('../Pickles/x_test.p', 'rb'))\n",
    "    y_train = pickle.load(open('../Pickles/y_train.p', 'rb'))\n",
    "    y_test = pickle.load(open('../Pickles/y_test.p', 'rb'))\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = get_pickles()\n",
    "print(x_train.shape, x_test.shape) \n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling\n",
    "- 0 = negative\n",
    "- 1 = neutral \n",
    "- 2 = positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Train Value Counts\n",
      "1.0    4041\n",
      "2.0    2233\n",
      "0.0     428\n",
      "Name: Emotion_New, dtype: int64\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original Test Value Counts\n",
      "1.0    1347\n",
      "2.0     745\n",
      "0.0     142\n",
      "Name: Emotion_New, dtype: int64\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Final Resampled Value Counts\n",
      "1.0    500\n",
      "2.0    500\n",
      "0.0    428\n",
      "Name: target, dtype: int64\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "print('Original Train Value Counts')\n",
    "print(y_train.value_counts())\n",
    "print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "print('Original Test Value Counts')\n",
    "print(y_test.value_counts())\n",
    "print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "\n",
    "\n",
    "train_df = pd.DataFrame(x_train)\n",
    "train_df['target'] = y_train.values \n",
    "\n",
    "neg_df = train_df[train_df.target == 0]\n",
    "neut_df = train_df[train_df.target == 1]\n",
    "pos_df = train_df[train_df.target == 2]\n",
    "\n",
    "\n",
    "\n",
    "resample_pos = resample(pos_df, n_samples = 500, random_state = 10, replace = True)\n",
    "resample_neut = resample(neut_df, n_samples = 500, random_state = 10, replace = True)\n",
    "\n",
    "final_df= neg_df.append(resample_pos, ignore_index = True)\n",
    "final_df = final_df.append(resample_neut, ignore_index = True)\n",
    "print('Final Resampled Value Counts')\n",
    "print(final_df.target.value_counts())\n",
    "print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "\n",
    "\n",
    "x_train_new = final_df[[i for i in final_df.columns if i != 'target']]\n",
    "y_train_new = final_df[['target']].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating STACKED:  90%|█████████████████████████████████████████████████████████████████████████████████         | 9/10 [02:54<00:18, 18.16s/it]"
     ]
    }
   ],
   "source": [
    "models = {'DT': DecisionTreeClassifier(), 'Gaussian': GaussianNB(), 'LDA': LinearDiscriminantAnalysis(),\n",
    "           'LinearSVC': LinearSVC(max_iter = 1250), 'SDGSVC': SGDClassifier(),  \n",
    "          'ADA': AdaBoostClassifier(), 'Bagging': BaggingClassifier(), 'Ridge': RidgeClassifier(), \n",
    "          'RF': RandomForestClassifier()}\n",
    "\n",
    "#create stacked model\n",
    "stack_m = [] \n",
    "for model, m in models.items(): \n",
    "    stack_m.append((model, m))\n",
    "stack_model = StackingClassifier(estimators = stack_m, final_estimator = LogisticRegression(), cv = 5)\n",
    "models['stacked'] = stack_model\n",
    "\n",
    "#test each model and stacking\n",
    "results = []\n",
    "model_names = []\n",
    "pbar = tqdm(models.items())\n",
    "for model, m in pbar: \n",
    "    pbar.set_description(f'Evaluating {model.upper()}')\n",
    "    cv = RepeatedStratifiedKFold(n_splits = 5, n_repeats = 5)\n",
    "    scores = cross_val_score(m, x_train_new, y_train_new, scoring = 'accuracy', cv = cv, n_jobs = 12, \n",
    "                             error_score = 'raise')\n",
    "    results.append(scores)\n",
    "    model_names.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_dict = {i:y for i,y in zip(model_names, results)}\n",
    "pickle.dump(vanilla_dict, open('models/VanillaResults.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,8))\n",
    "plt.boxplot(results, labels = model_names, showmeans = True)\n",
    "plt.title('Accuracy for Each Vanilla Model')\n",
    "plt.ylabel('Accuracy'); plt.xlabel('Model')\n",
    "plt.savefig('figures/BaselineAccuracy.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state = 10, n_jobs = -1)\n",
    "\n",
    "rf.fit(x_train_new, y_train_new)\n",
    "\n",
    "train_pred = rf.predict(x_train_new)\n",
    "test_pred = rf.predict(x_test)\n",
    "\n",
    "print('Vanilla Random Forest')\n",
    "print(f'Train Accuracy: {rf.score(x_train_new, y_train_new)}')\n",
    "print(f'Test Accuracy: {rf.score(x_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
