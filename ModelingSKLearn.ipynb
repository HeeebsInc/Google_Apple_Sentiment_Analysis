{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In c:\\users\\heeeb\\anaconda3\\envs\\codeacademy\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In c:\\users\\heeeb\\anaconda3\\envs\\codeacademy\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In c:\\users\\heeeb\\anaconda3\\envs\\codeacademy\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In c:\\users\\heeeb\\anaconda3\\envs\\codeacademy\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In c:\\users\\heeeb\\anaconda3\\envs\\codeacademy\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In c:\\users\\heeeb\\anaconda3\\envs\\codeacademy\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In c:\\users\\heeeb\\anaconda3\\envs\\codeacademy\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In c:\\users\\heeeb\\anaconda3\\envs\\codeacademy\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier, RidgeClassifier, LogisticRegression \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, plot_confusion_matrix, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "from Functions import *\n",
    "\n",
    "\n",
    "pd.options.display.max_rows = 35 \n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/TweetsOriginal.csv', encoding = 'ISO-8859-1')\n",
    "x_train, x_test, y_train, y_test = clean_split(df)\n",
    "print(x_train.shape, x_test.shape) \n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'Log': LogisticRegression(), 'Knn': KNeighborsClassifier(), 'DT': DecisionTreeClassifier(random_state = 10), \n",
    "          'Gaussian': GaussianNB(), 'Multinomail': MultinomialNB(), 'LDA': LinearDiscriminantAnalysis(),\n",
    "          'LinearSVC': LinearSVC(max_iter = 1250, random_state = 10), 'SDGSVC': SGDClassifier(random_state = 10),  \n",
    "          'ADA': AdaBoostClassifier(random_state = 10), 'Bagging': BaggingClassifier(random_state = 10), \n",
    "          'Ridge': RidgeClassifier(random_state = 10), 'RF': RandomForestClassifier(random_state = 10)}\n",
    "\n",
    "#create stacked model\n",
    "new_models = stacked_model(models)\n",
    "\n",
    "# getting results and model\n",
    "result_dict = test_models(x_train, y_train, new_models, n_jobs = 13)\n",
    "\n",
    "save_cv_results(result_dict, 'models/VanillaResults1.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [i[1] for i in result_dict.items()]\n",
    "model_names = [i for i in result_dict.keys()]\n",
    "plot_model_results(results, model_names, 'figures/VanillaResults1', figure_title = 'Accuracy for Each Vanilla Model (version 1)', \n",
    "                   figsize = (13, 8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'Log': LogisticRegression(), 'Gaussian': GaussianNB(), 'Multinomial': MultinomialNB(),\n",
    "          'LinearSVC': LinearSVC(max_iter = 1250, random_state = 10), 'SDGSVC': SGDClassifier(random_state = 10),  \n",
    "          'ADA': AdaBoostClassifier(random_state = 10), 'Bagging': BaggingClassifier(random_state = 10), \n",
    "          'Ridge': RidgeClassifier(random_state = 10), 'RF': RandomForestClassifier(random_state = 10)}\n",
    "\n",
    "#create stacked model\n",
    "new_models = stacked_model(models)\n",
    "\n",
    "# getting results and model\n",
    "result_dict = test_models(x_train, y_train, new_models, n_jobs = -1)\n",
    "\n",
    "save_cv_results(result_dict, 'models/VanillaResults2.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [i[1] for i in result_dict.items()]\n",
    "model_names = [i for i in result_dict.keys()]\n",
    "plot_model_results(results, model_names, 'figures/VanillaResults2', figure_title = 'Accuracy for Each Vanilla Model (version 2)', \n",
    "                   figsize = (10, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key, item in pickle.load(open('../Pickles/ClassificationReport.p', 'rb')).items():\n",
    "#     print(key)\n",
    "#     print(item) \n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Each Model Above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_log = LogisticRegression()\n",
    "vanilla_log.fit(x_train, y_train) \n",
    "\n",
    "print(f'Vanilla Train: {vanilla_log.score(x_train, y_train)}')\n",
    "print(f'Vanilla Test: {vanilla_log.score(x_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_grid = { \n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'dual': [True, False],\n",
    "    'tol': [1e-3, 1e-4, 1e-5],\n",
    "    'C': [.5, 1],\n",
    "    'intercept_scaling': [.5, 1, 1.5],\n",
    "    'class_weight': ['balanced', None],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'max_iter': [100, 1000],\n",
    "    'l1_ratio': [None, .5],\n",
    "}\n",
    "\n",
    "log_cv = run_gridsearch(LogisticRegression(), x_train, y_train, x_test, y_test, param_grid, n_jobs = -1, verbose = 2)\n",
    "pickle.dump(log_cv, open('../Pickles/Grid_Logistic.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_multinb = MultinomialNB()\n",
    "vanilla_multinb.fit(x_train, y_train) \n",
    "\n",
    "print(f'Vanilla Train: {vanilla_multinb.score(x_train, y_train)}')\n",
    "print(f'Vanilla Test: {vanilla_multinb.score(x_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid ={\n",
    "    'alpha': [.1, .25, .5, 1, 1.5, 2], \n",
    "    'fit_prior': [True, False]\n",
    "}\n",
    "multinb_cv = run_gridsearch(MultinomialNB(), x_train, y_train, x_test, y_test, param_grid, n_jobs = -1, verbose = 2)\n",
    "pickle.dump(multinb_cv, open('../Pickles/Grid_MultiNB.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_sgd = SGDClassifier(random_state = 10)\n",
    "vanilla_sgd.fit(x_train, y_train)\n",
    "\n",
    "print(f'Vanilla Train: {vanilla_sgd.score(x_train, y_train)}')\n",
    "print(f'Vanilla Test: {vanilla_sgd.score(x_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'], \n",
    "    'loss': ['hinge', 'squared_hinge', 'log', 'modified_huber', 'perceptron'],\n",
    "    'alpha': [.001, .0001, .00001],\n",
    "    'l1_ratio': [.01, .15, .5], \n",
    "    'max_iter': [1000, 2000], \n",
    "    'tol': [1e-2, 1e-3, 1e-4],\n",
    "    'shuffle': [True, False],\n",
    "    'epsilon': [.05, .1, .5],\n",
    "    'power_t': [.1, .5, 1], \n",
    "    'n_iter_no_change': [5,10],\n",
    "    'average': [True, False]\n",
    "    \n",
    "}\n",
    "sgd_cv = run_gridsearch(SGDClassifier(random_state = 10), x_train, y_train, x_test, y_test, param_grid, n_jobs = -1,\n",
    "                        verbose = 2)\n",
    "pickle.dump(sgd_cv, open('../Pickles/Grid_SGD.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_svc = LinearSVC(random_state = 10)\n",
    "vanilla_svc.fit(x_train, y_train)\n",
    "\n",
    "print(f'Vanilla Train: {vanilla_svc.score(x_train, y_train)}')\n",
    "print(f'Vanilla Test: {vanilla_svc.score(x_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'], \n",
    "    'loss': ['hinge', 'squared_hinge'],\n",
    "    'dual': [True, False],\n",
    "    'tol': [1e-3, 1e-4, 1e-5],\n",
    "    'C': [.5, 1.0, 1.5],\n",
    "    'intercept_scaling': [.5, 1, 1.5],\n",
    "    'max_iter': [1000, 2000]\n",
    "}\n",
    "\n",
    "svc_cv = run_gridsearch(LinearSVC(random_state = 10), x_train, y_train, x_test, y_test, param_grid, n_jobs = -1,\n",
    "                        verbose = 2)\n",
    "pickle.dump(svc_cv, open('../Pickles/Grid_SVC.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_ridge = RidgeClassifier(random_state = 10)\n",
    "vanilla_ridge.fit(x_train, y_train)\n",
    "\n",
    "print(f'Vanilla Train: {vanilla_ridge.score(x_train, y_train)}')\n",
    "print(f'Vanilla Test: {vanilla_ridge.score(x_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha': [.5, 1.0, 1.5], \n",
    "    'normalize': [True, False], \n",
    "    'tol': [1e-2, 1e-3, 1e-4], \n",
    "    'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'], \n",
    "    \n",
    "}\n",
    "ridge_cv = run_gridsearch(RidgeClassifier(random_state = 10), x_train, y_train, x_test, y_test, param_grid, n_jobs = -1,\n",
    "                        verbose = 2)\n",
    "pickle.dump(ridge_cv, open('../Pickles/Grid_Ridge.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_rf = RandomForestClassifier(random_state = 10)\n",
    "vanilla_rf.fit(x_train, y_train)\n",
    "\n",
    "print(f'Vanilla Train: {vanilla_rf.score(x_train, y_train)}')\n",
    "print(f'Vanilla Test: {vanilla_rf.score(x_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150], \n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 100, 200, 500],\n",
    "    'min_samples_split': [2, 3, 5], \n",
    "    'min_samples_leaf': [1,2,5],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_leaf_nodes': [None, 100, 200],\n",
    "    'bootstrap': [True, False], \n",
    "    'class_weight': [None, 'balanced', 'balanced_subsample'],\n",
    "    'ccp_alpha': [0.0, .5, 1.0]\n",
    "\n",
    "    \n",
    "    \n",
    "}\n",
    "rf_cv = run_gridsearch(RandomForestClassifier(random_state = 10), x_train, y_train, x_test, y_test, param_grid, n_jobs = -1,\n",
    "                        verbose = 2)\n",
    "pickle.dump(rf_cv, open('../Pickles/Grid_RF.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_dict = {'log': log_cv, 'multi': multnb_cv, 'sgd': sgd_cv, 'svc': svc_cv, 'ridge': ridge_cv}\n",
    "pickle.dump(cv_dict, open('../Pickles/CombinedCV.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_ada = BaggingClassifier(random_state = 10)\n",
    "vanilla_ada.fit(x_train, y_train)\n",
    "\n",
    "print(f'Vanilla Train: {vanilla_ada.score(x_train, y_train)}')\n",
    "print(f'Vanilla Test: {vanilla_ada.score(x_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_ada = AdaBoostClassifier(random_state = 10)\n",
    "vanilla_ada.fit(x_train, y_train)\n",
    "\n",
    "print(f'Vanilla Train: {vanilla_ada.score(x_train, y_train)}')\n",
    "print(f'Vanilla Test: {vanilla_ada.score(x_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'base_estimator': [LogisticRegression(),  None, RandomForestClassifier(random_state = 10), \n",
    "                       DecisionTreeClassifier(random_state = 10)], \n",
    "    'n_estimators': [25, 50, 100], \n",
    "    'learning_rate': [.5, 1, 1.5], \n",
    "    'algorithm': ['SAMME', 'SAMME.R'], \n",
    "     \n",
    "}\n",
    "ada_cv = run_gridsearch(AdaBoostClassifier(random_state = 10), x_train, y_train, x_test, y_test, param_grid, n_jobs = -1,\n",
    "                        verbose = 2)\n",
    "pickle.dump(ada_cv, open('../Pickles/Grid_ADA.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'Log': LogisticRegression(C= 0.5, class_weight= None, \n",
    "                                    dual= False, intercept_scaling= 1, max_iter= 1000, \n",
    "                                    penalty= 'l2', solver= 'sag', tol= 0.0001), \n",
    "          'Multinomail': MultinomialNB(alpha = .5),\n",
    "          'LinearSVC': LinearSVC(C = .5, intercept_scaling = .5, tol = .5, random_state = 10), \n",
    "          'SDGSVC': SGDClassifier(random_state = 10, alpha= 0.0001, average= True, \n",
    "                                  epsilon= 0.01, l1_ratio= 0.001, loss= 'log', \n",
    "                                  max_iter= 1000, n_iter_no_change= 5, \n",
    "                                  penalty= 'l1', power_t= 0.01, shuffle= False, tol= 0.1),  \n",
    "          'Ridge': RidgeClassifier(random_state = 10, alpha= 1.5, normalize= True, solver= 'lsqr', tol= 0.01), \n",
    "          'RF': RandomForestClassifier(random_state = 10, bootstrap= True, ccp_alpha= 0.0, \n",
    "                                       class_weight= 'balanced_subsample', criterion= 'gini', \n",
    "                                       max_depth= 50, max_features= 'log2', max_leaf_nodes= None, \n",
    "                                       min_samples_leaf= 1, min_samples_split= 5, n_estimators= 150)}\n",
    "\n",
    "#create stacked model\n",
    "new_models = stacked_model(models)\n",
    "\n",
    "# getting results and model\n",
    "result_dict = test_models(x_train, y_train, new_models, n_jobs = -1)\n",
    "\n",
    "save_cv_results(result_dict, 'models/FinalTunedResults.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [i[1] for i in result_dict.items()]\n",
    "model_names = [i for i in result_dict.keys()]\n",
    "plot_model_results(results, model_names, 'figures/VanillaResults3', figure_title = 'Accuracy for Tuned Models', \n",
    "                   figsize = (10, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Stacked Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_stacked = new_models['stacked']\n",
    "final_stacked = pickle.load(open('../Pickles/TunedStackedModel.p', 'rb'))\n",
    "final_stacked.fit(x_train, y_train)\n",
    "print(f'Tuned Stacked Train: {final_stacked.score(x_train, y_train)}')\n",
    "print(f'Tuned Stacked Test: {final_stacked.score(x_test, y_test)}')\n",
    "print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize = (10,5))\n",
    "\n",
    "cm_train = confusion_matrix(y_train, final_stacked.predict(x_train))\n",
    "cm_test = confusion_matrix(y_test, final_stacked.predict(x_test))\n",
    "\n",
    "sns.heatmap(cm_train, annot = True, ax = ax[0], xticklabels = ['Negative', 'Positive'], \n",
    "            yticklabels = ['Negative', 'Positive'], cmap = 'Blues', cbar = False, fmt = 'g')\n",
    "sns.heatmap(cm_test, annot = True, ax = ax[1], xticklabels = ['Negative', 'Positive'], \n",
    "            yticklabels = ['Negative', 'Positive'], cmap = 'Blues', cbar = False, fmt = 'g')\n",
    "\n",
    "\n",
    "ax[0].set_title('Train')\n",
    "ax[1].set_title('Test')\n",
    "\n",
    "plt.savefig('figures/StackedTunedCM.png')\n",
    "plt.show()\n",
    "\n",
    "pickle.dump(final_stacked, open('../Pickles/TunedStackedModel.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cr_dict = {'train': classification_report(y_train, final_stacked.predict(x_train), target_names = ['Negative', 'Positive']), \n",
    "          'test': classification_report(y_test, final_stacked.predict(x_test), target_names = ['Negative', 'Positive'])}\n",
    "\n",
    "\n",
    "pickle.dump(cr_dict, open('../Pickles/ClassificationReport.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "columns = pd.read_csv('data/TrainDF.csv').columns.tolist()\n",
    "est_dict = final_stacked.named_estimators\n",
    "word_import = {}\n",
    "for i in final_stacked.named_estimators_: \n",
    "    mod = est_dict[i]\n",
    "    smf = SelectFromModel(mod, threshold = - np.inf, max_features = 10)\n",
    "    smf.fit(x_train, y_train)\n",
    "    feature_idx = smf.get_support()\n",
    "    feature_names = [columns[idx] for (idx, i) in enumerate(feature_idx) if i == True]\n",
    "    word_import[i] = feature_names\n",
    "\n",
    "print(word_import)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime import lime_text\n",
    "import lime.lime_tabular\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "df =pd.read_csv('data/TestDF.csv')\n",
    "columns = df.columns.tolist()\n",
    "feat = [i for i in columns if i not in ['target', 'Item']]\n",
    "\n",
    "\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(df[[i for i in columns if i not in ['target', 'Item']]].values,\n",
    "                                                   mode = 'classification', \n",
    "                                                  training_labels = df.target.values, \n",
    "                                                   feature_names = feat, random_state = 10, \n",
    "                                              )\n",
    "\n",
    "i = 10\n",
    "labels = ['Negative', 'Positive']\n",
    "row = df.loc[i, feat].values\n",
    "exp = explainer.explain_instance(row, final_stacked.predict_proba, num_features = 15) \n",
    "sent = ' '.join([feat[idx] for (idx, i) in enumerate(row) if i ==1])\n",
    "pred = final_stacked.predict(row.reshape(1,-1))[0]\n",
    "# print(f'Original Tokenized/Stemmed Tweet:\\n\\t\\t\"{sent}\"')\n",
    "# print(f'Actual Label:\\n\\t\\t{labels[int(pred)]}')\n",
    "exp.show_in_notebook(show_table = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = exp.as_pyplot_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime import submodular_pick\n",
    "\n",
    "sp_obj = submodular_pick.SubmodularPick(explainer, df[[i for i in columns if i not in ['target', 'Item']]].values, \n",
    "                                       final_stacked.predict_proba, num_features = 10, \n",
    "                                       num_exps_desired = 10)\n",
    "[exp.as_pyplot_figure(label = 1) for exp in sp_obj.sp_explanations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
